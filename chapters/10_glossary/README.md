# Glossary of LLM Terms

This chapter provides a comprehensive glossary of key terms and concepts related to Large Language Models (LLMs).

## A

-   **Attention:** A mechanism that allows a neural network to focus on specific parts of an input sequence when processing it.

## B

-   **BERT (Bidirectional Encoder Representations from Transformers):** A transformer-based model that learns context from both the left and right side of a token in a sequence.

## C

-   **Context Window:** The maximum number of tokens a model can consider at once when processing a sequence.

## D

-   **Decoding:** The process of generating a sequence of tokens from a model's internal representation.

## E

-   **Embedding:** A dense vector representation of a token, word, or sentence.

## F

-   **Fine-tuning:** The process of adapting a pre-trained model to a specific task by training it on a smaller, task-specific dataset.
    -   **Full-Model Fine-Tuning (FMFT):** A fine-tuning approach where all the parameters of the pre-trained model are updated.
    -   **Parameter-Efficient Fine-Tuning (PEFT):** A set of techniques that only fine-tunes a small number of model parameters, significantly reducing computational and storage costs.

## G

-   **GPT (Generative Pre-trained Transformer):** A family of transformer-based models that are pre-trained on a large corpus of text and can be fine-tuned for various natural language processing tasks.

## H

-   **Hallucination:** A phenomenon where an LLM generates text that is factually incorrect or nonsensical.

## I

-   **In-context Learning:** The ability of a model to learn a new task from a few examples provided in the input prompt.
-   **Inference:** The process of using a trained model to make predictions or generate text.

## L

-   **LangChain:** A framework for developing applications powered by language models.
-   **LLM (Large Language Model):** A type of neural network with a large number of parameters that is trained on a massive amount of text data.
-   **LlamaIndex:** A data framework for LLM applications to ingest, structure, and access private or domain-specific data.

## P

-   **Prompt Design:** The process of structuring a prompt to guide the LLM towards a specific type of output. It's a subset of prompt engineering.
-   **Prompt Engineering:** The art of designing effective prompts to elicit desired responses from an LLM.
-   **Prompting:** The act of providing an input (a prompt) to an LLM to get a response.

## R

-   **RAG (Retrieval-Augmented Generation):** A technique that combines a retrieval system with a generative model to produce more accurate and contextually relevant responses.

## T

-   **Transformer:** A neural network architecture that relies on self-attention mechanisms to process sequences of data.
-   **Tokenization:** The process of breaking down a text into smaller units called tokens.

## V

-   **Vector Database:** A specialized database designed to store and query high-dimensional vectors, such as those produced by embedding models.
-   **Vector Store:** A more general term for a system that stores and retrieves vectors. It can be a full-fledged vector database or a simpler in-memory index.
